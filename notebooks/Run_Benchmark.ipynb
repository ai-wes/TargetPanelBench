{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5941da60",
   "metadata": {},
   "source": [
    "# TargetPanelBench Demo\n",
    "This notebook demonstrates how to load the synthetic dataset, run the baseline methods, and compare their performance to the precomputed results from the proprietary Adaptive Ensemble Algorithm (AEA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9df6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import pandas as pd\n",
    "import json\n",
    "from evaluation import compute_ranking_metrics, panel_recall, panel_diversity_score, build_adjacency\n",
    "from panel_design import select_top_k, select_diverse_panel\n",
    "from baselines.simple_score_rank import run_simple_baseline\n",
    "from baselines.cma_es import run_cma_es_baseline\n",
    "\n",
    "# Load dataset\n",
    "targets = pd.read_csv('../data/targets.csv')\n",
    "edges = pd.read_csv('../data/ppi_edges.csv')\n",
    "adjacency = build_adjacency(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simple sum-of-features baseline\n",
    "simple_results = run_simple_baseline('../data/targets.csv', '../data/ppi_edges.csv', panel_size=12, k=20)\n",
    "print('Simple baseline metrics:')\n",
    "print(simple_results['metrics'])\n",
    "print('Panel recall:', simple_results['panel_recall'])\n",
    "print('Panel diversity:', simple_results['panel_diversity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758620e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evolutionary baseline\n",
    "cma_results = run_cma_es_baseline('../data/targets.csv', '../data/ppi_edges.csv', iterations=50, objective='ndcg', panel_size=12, k=20, seed=42)\n",
    "print('CMA-ES baseline metrics:')\n",
    "print(cma_results['metrics'])\n",
    "print('Panel recall:', cma_results['panel_recall'])\n",
    "print('Panel diversity:', cma_results['panel_diversity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed AEA results\n",
    "with open('../results/aea_results.json') as f:\n",
    "    aea_results = json.load(f)\n",
    "print('AEA metrics:')\n",
    "print(aea_results['metrics'])\n",
    "print('Panel recall:', aea_results['panel_recall'])\n",
    "print('Panel diversity:', aea_results['panel_diversity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics from all methods\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Method': ['Simple', 'CMA-ES', 'AEA'],\n",
    "    'Precision@20': [simple_results['metrics']['precision_at_20'], cma_results['metrics']['precision_at_20'], aea_results['metrics']['precision_at_20']],\n",
    "    'MRR': [simple_results['metrics']['mrr'], cma_results['metrics']['mrr'], aea_results['metrics']['mrr']],\n",
    "    'nDCG@20': [simple_results['metrics']['ndcg_at_20'], cma_results['metrics']['ndcg_at_20'], aea_results['metrics']['ndcg_at_20']],\n",
    "    'Panel Recall': [simple_results['panel_recall'], cma_results['panel_recall'], aea_results['panel_recall']],\n",
    "    'Panel Diversity': [simple_results['panel_diversity'], cma_results['panel_diversity'], aea_results['panel_diversity']]\n",
    "})\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
